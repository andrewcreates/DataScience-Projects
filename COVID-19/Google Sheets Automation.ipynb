{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import gspread\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv'\n",
    "url2 = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv'\n",
    "df_usconf = pd.read_csv(url,error_bad_lines = False)\n",
    "df_usdead = pd.read_csv(url2,error_bad_lines = False)\n",
    "\n",
    "df_counties = pd.read_csv(r'X:\\AC\\Documents\\Datasets\\US Census and OMB Data\\2020 Counties UID State CBSA CSA.csv', delimiter = ',', encoding = \"ISO-8859-1\")\n",
    "df_counties = df_counties[['UID', 'CBSA Code', 'CBSA Title', 'CSA Code', 'CSA Title']]\n",
    "\n",
    "#Add CBSA/CSA titles and codes to df\n",
    "df_usconf = df_usconf.merge(df_counties, on = 'UID', how = 'left', suffixes=(False,False))\n",
    "df_usconf = df_usconf.merge(df_usdead[['UID','Population']], on = 'UID', how = 'left', suffixes=(False,False))\n",
    "cols = df_usconf.columns.tolist()\n",
    "df_usconf = df_usconf[cols[0:1] + cols[-1:] + cols[5:6] + cols[6:8] + cols[-5:-1] + cols[11:-5]]\n",
    "\n",
    "#replace NaNs with ''\n",
    "df_usconf.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guam, American Samoa, Diamond/Grand Princess, Northern Mariana Islands, Virgin islands all have NaN in Admin2\n",
    "#Removing nan in Admin2 column so that I can combine 'Out of' and 'Unassigned' Admin2\n",
    "df_usconf.loc[df_usconf['Admin2'].isna(),'Admin2'] = ''\n",
    "\n",
    "#loop to combine 'Out of *' and 'Unassigned' Admin2's\n",
    "dates = df_usconf.columns[9:].tolist()\n",
    "for state in df_usconf.loc[df_usconf['Admin2'].str.contains('Unassigned'),'Province_State'].unique():\n",
    "    a = df_usconf.loc[(df_usconf['Admin2'].str.contains('Unassigned')) & (df_usconf['Province_State']==state)]\n",
    "    b = df_usconf.loc[(df_usconf['Admin2'].str.contains('Out of')) & (df_usconf['Province_State']==state)]\n",
    "    df_usconf.loc[(df_usconf['Admin2'].str.contains('Unassigned')) & (df_usconf['Province_State']==state), dates]= a.iloc[:,9:].values + b.iloc[:,9:].values\n",
    "    df_usconf = df_usconf.drop(b.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert date columns into a single column for cumulative totals df\n",
    "df_usconf_pivot = df_usconf.melt(id_vars = df_usconf.columns[:9], var_name = 'Date', value_name = 'Total Confirmed Cases').sort_values(by = ['UID','Date']).reset_index(drop=True)\n",
    "df_usdead_pivot = df_usdead.melt(id_vars = df_usdead.columns[:12], var_name = 'Date', value_name = 'Total Dead').sort_values(by = ['UID','Date']).reset_index(drop=True)\n",
    "\n",
    "#create df for daily increments\n",
    "df_usconf_daily = df_usconf.copy()\n",
    "df_usdead_daily = df_usdead.copy()\n",
    "df_usconf_daily.iloc[:,9:] = df_usconf_daily.iloc[:,9:].diff(axis=1).fillna(0).astype('int')\n",
    "df_usdead_daily.iloc[:,12:] = df_usdead_daily.iloc[:,12:].diff(axis=1).fillna(0).astype('int')\n",
    "\n",
    "#convert date columns into a single column for daily increments\n",
    "df_usconf_daily = df_usconf_daily.melt(id_vars = df_usconf_daily.columns[:9], var_name = 'Date', value_name = 'Daily Confirmed Cases').sort_values(by = ['UID','Date']).reset_index(drop=True)\n",
    "df_usdead_daily = df_usdead_daily.melt(id_vars = df_usdead_daily.columns[:12], var_name = 'Date', value_name = 'Daily Dead').sort_values(by = ['UID','Date']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine cumulative totals for deaths and confirmed cases into one df\n",
    "us_totals = df_usconf_pivot.merge(df_usdead_pivot[['UID','Date','Total Dead']], on = ['UID','Date'], how = 'left', suffixes = (False, False))\n",
    "us_totals['Date'] = pd.to_datetime(us_totals['Date']).apply(lambda x: pd.datetime.strftime(x, '%m/%d/%y'))\n",
    "us_totals = us_totals.sort_values(by = ['UID','Date']).reset_index(drop=True)\n",
    "\n",
    "#combine daily increase for deaths and confirmed cases into one df\n",
    "us_daily = df_usconf_daily.merge(df_usdead_daily[['UID','Date','Daily Dead']], on = ['UID','Date'], how = 'left', suffixes = (False, False))\n",
    "us_daily['Date'] = pd.to_datetime(us_daily['Date']).apply(lambda x: pd.datetime.strftime(x, '%m/%d/%y'))\n",
    "us_daily = us_daily.sort_values(by = ['UID','Date']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to review all features required for viz\n",
    "# Combined observations (out of state, unassigned)\n",
    "# replace np.nan with ''\n",
    "# Load all values into gspread\n",
    "# How to incrementally update instead of updating everything\n",
    "\n",
    "#3288 different state/Admin2 groupings\n",
    "#125-126 Dates can fit in one google spreadsheet\n",
    "#Update seems limited to ~55 dates (2.2M cells), even though it's well bellow then 5M cell limit/sheet\n",
    "    #this was due to the other columns that were prepopulated. Delete these prior to update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spreadsheet already updated\n"
     ]
    }
   ],
   "source": [
    "#Daily update for spreadsheet 2\n",
    "#Date range is ordered from oldest to newest\n",
    "gc = gspread.service_account(filename='./covid-19-data/client_secret.json')\n",
    "sheet2 = gc.open(\"COVID Tableau Automation 2\").sheet1\n",
    "\n",
    "if us_daily['Date'].max() in sheet2.col_values(10):\n",
    "    print('Spreadsheet already updated')\n",
    "else:\n",
    "    if us_daily['Date'].max() in (us_daily['Date'].unique()[125:250]):\n",
    "        us_daily_2 = us_daily.copy().loc[us_daily['Date']==us_daily['Date'].max()]\n",
    "        sheet2.append_rows(us_daily_2.values.tolist())\n",
    "    else:\n",
    "        print('You reached the spreadsheet limit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statedaily = us_daily.loc[~us_daily['Province_State'].isin(['Diamond Princess','Grand Princess'])].groupby(['Province_State','Date'], as_index=False)['Population','Daily Confirmed Cases'].sum()\n",
    "statedaily = statedaily.sort_values(['Date','Province_State'], ascending = [False,True]).reset_index(drop=True)\n",
    "statecumsum = us_totals.groupby(['Province_State','Date'], as_index=False)['Total Confirmed Cases','Total Dead'].sum()\n",
    "stategrp = pd.merge(statedaily, statecumsum, on = ['Province_State','Date'], how = 'left', suffixes = (False, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature creation, rankings\n",
    "stategrp['Total Cases per 1000 capita'] = stategrp['Total Confirmed Cases']/stategrp['Population']*1000\n",
    "\n",
    "ranks = []\n",
    "for date in stategrp['Date'].unique():\n",
    "    for ranking in stategrp.copy().loc[stategrp['Date']==date,'Total Confirmed Cases'].rank(ascending = False, method='min'):\n",
    "        ranks.append(ranking)\n",
    "rankings = pd.DataFrame({'Total Cases Daily Ranking': ranks})\n",
    "stategrp = pd.concat([stategrp, rankings], axis=1)\n",
    "\n",
    "dates = stategrp['Date'].unique().tolist()\n",
    "ustemp = pd.DataFrame()\n",
    "for state in stategrp['Province_State'].unique():\n",
    "    statetemp = stategrp.loc[stategrp['Province_State']==state].copy().reset_index(drop=True)\n",
    "    yest = pd.Series(statetemp.loc[statetemp['Date'].isin(dates[1:]),'Total Cases Daily Ranking'].reset_index(drop=True)).rename('Total Cases Ranking Daily Change')\n",
    "    statetemp = pd.concat([statetemp,yest], axis=1)\n",
    "    ustemp = pd.concat([ustemp, statetemp])\n",
    "\n",
    "stategrp = ustemp.sort_values(['Date','Total Cases Daily Ranking'], ascending = [False,True]).reset_index(drop=True)\n",
    "stategrp['Total Cases Ranking Daily Change'] = stategrp['Total Cases Ranking Daily Change'] - stategrp['Total Cases Daily Ranking']\n",
    "\n",
    "ranks = []\n",
    "for date in stategrp['Date'].unique():\n",
    "    for ranking in stategrp.copy().loc[stategrp['Date']==date,'Daily Confirmed Cases'].rank(ascending = False, method='min'):\n",
    "        ranks.append(ranking)\n",
    "rankings = pd.DataFrame({'Daily Cases Ranking': ranks})\n",
    "stategrp = pd.concat([stategrp, rankings], axis=1)\n",
    "\n",
    "ranks = []\n",
    "for date in stategrp['Date'].unique():\n",
    "    for ranking in stategrp.copy().loc[stategrp['Date']==date,'Total Cases per 1000 capita'].rank(ascending = False, method='min'):\n",
    "        ranks.append(ranking)\n",
    "rankings = pd.DataFrame({'Cases per Capita Ranking': ranks})\n",
    "stategrp = pd.concat([stategrp, rankings], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_total = us_daily['Daily Confirmed Cases'].sum()\n",
    "conf_dead = us_daily['Daily Dead'].sum()\n",
    "US_pop = 329943320 #as of 1/1/20\n",
    "\n",
    "\n",
    "print('US Stats As of: ', us_totals['Date'].sort_values(ascending = True).to_list()[-1])\n",
    "print('Total Confirmed Cases To Date: ', conf_total)\n",
    "print('Confirmed Cases Percentage of US population: %.2f' %((conf_total/ US_pop) * 100),'%')\n",
    "print('\\n')\n",
    "print('Total Deaths To Date: ', (conf_dead))\n",
    "print('Confirmed Cases Percentage of US population: %.2f' %((conf_dead/ US_pop) * 100),'%')\n",
    "print('Percentage of deaths from confirmed cases : %.2f' %((conf_dead/ US_pop)/(conf_total/ US_pop)*100),'%')\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last14 = us_daily['Date'].values.tolist()[-14:]\n",
    "prev2weekavg = us_daily.loc[(us_daily['Date'].isin(us_daily['Date'].values.tolist()[-15:-1]))].groupby('Date')['Daily Confirmed Cases'].sum().mean()\n",
    "yestsum = us_daily.loc[(us_daily['Date']==us_daily['Date'].unique()[-1])]['Daily Confirmed Cases'].sum()\n",
    "\n",
    "print('For Yesterday ({}):'.format(us_daily['Date'].unique()[-1]))\n",
    "print('Increase in Total Confirmed Cases: ', yestsum)\n",
    "print('Percentage increase from average of last two weeks: ', ((yestsum - prev2weekavg)/prev2weekavg * 100), '%')\n",
    "print('\\n')\n",
    "print('Last 14 days:')\n",
    "print('Total Confirmed Cases: ', us_daily.loc[(us_daily['Date'].isin(last14))]['Daily Confirmed Cases'].sum())\n",
    "print('Average Cases per day: %.1f' %prev2weekavg)\n",
    "print('Cases in Last 14 days as Percentage of Total Cases: %.2f' %((us_daily.loc[(us_daily['Date'].isin(last14))]['Daily Confirmed Cases'].sum()/(conf_total))*100),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_daily.to_csv(r'X:\\AC\\Documents\\Datasets\\US_daily_pivot.csv', index=False)\n",
    "us_totals.to_csv(r'X:\\AC\\Documents\\Datasets\\US_totals_pivot.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create extract for google sheets\n",
    "#consider removing 'Northern Mariana Islands, Guam, American Samoa, Diamond Princess, Grand Princess Virgin Islands, Virginn Islands' to save space\n",
    "#will need to split into multiple sheets\n",
    "#consolidate the Admin2s: 'Out of *, Unassigned' They seem to be staging values, all balance out to 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stategrp[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top daily increases by state\n",
    "stategrp.sort_values(by='Daily Confirmed Cases', ascending = False)[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top daily increases of cases per capita\n",
    "stategrp.assign(x = stategrp['Daily Confirmed Cases']/stategrp['Population']).sort_values(by='x', ascending = False).drop('x',axis=1)[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top daily increases by county\n",
    "us_daily.sort_values(by=['Daily Confirmed Cases'], ascending = False)[['Province_State','Admin2','Date','Population','Daily Confirmed Cases','Daily Dead']][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CA Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_daily.loc[(us_daily['Province_State']=='California')&(us_daily['Admin2']=='San Francisco'),['Date','Daily Confirmed Cases']].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top daily increases for CA\n",
    "stategrp.loc[stategrp['Province_State']=='California'].sort_values(by=['Daily Confirmed Cases'], ascending = False)[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create df for CA's CBSAs\n",
    "cacbsa_daily = us_daily.loc[(us_daily['Province_State']=='California')].groupby(['Province_State','CBSA Title','Date'], as_index=False)['Population','Daily Confirmed Cases'].sum()\n",
    "cacbsa_daily = cacbsa_daily.sort_values(['Date','Daily Confirmed Cases'], ascending = [False,False]).reset_index(drop=True)\n",
    "cacbsa_cumsum = us_totals.loc[us_totals['Province_State']=='California'].groupby(['Province_State','CBSA Title','Date'], as_index=False)['Total Confirmed Cases','Total Dead'].sum()\n",
    "cacbsa = pd.merge(cacbsa_daily, cacbsa_cumsum, on = ['Province_State','CBSA Title','Date'], how = 'left', suffixes = (False, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature creation, rankings\n",
    "cacbsa['Total Cases per 1000 capita'] = cacbsa['Total Confirmed Cases']/cacbsa['Population']*1000\n",
    "\n",
    "ranks = []\n",
    "for date in cacbsa['Date'].unique():\n",
    "    for ranking in cacbsa.copy().loc[cacbsa['Date']==date,'Total Confirmed Cases'].rank(ascending = False, method='min'):\n",
    "        ranks.append(ranking)\n",
    "rankings = pd.DataFrame({'Total Cases Daily Ranking': ranks})\n",
    "cacbsa = pd.concat([cacbsa, rankings], axis=1)\n",
    "\n",
    "dates = cacbsa['Date'].unique().tolist()\n",
    "cacbsatemp = pd.DataFrame()\n",
    "for state in cacbsa['CBSA Title'].unique():\n",
    "    cbsatemp = cacbsa.loc[cacbsa['CBSA Title']==state].copy().reset_index(drop=True)\n",
    "    yest = pd.Series(cbsatemp.loc[cbsatemp['Date'].isin(dates[1:]),'Total Cases Daily Ranking'].reset_index(drop=True)).rename('Total Cases Ranking Daily Change')\n",
    "    cbsatemp = pd.concat([cbsatemp,yest], axis=1)\n",
    "    cacbsatemp = pd.concat([cacbsatemp, cbsatemp])\n",
    "    \n",
    "cacbsa = cacbsatemp.sort_values(['Date','Total Cases Daily Ranking'], ascending = [False,True]).reset_index(drop=True)\n",
    "cacbsa['Total Cases Ranking Daily Change'] = cacbsa['Total Cases Ranking Daily Change'] - cacbsa['Total Cases Daily Ranking']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cacbsa.sort_values('Daily Confirmed Cases', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cacbsa.loc[cacbsa['Date']==cacbsa['Date'][0]][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Most recent day in SF Oakland Berkeley CBSA\n",
    "us_daily.loc[(us_daily['CBSA Title']=='San Francisco-Oakland-Berkeley, CA')&(us_daily['Date']==us_daily['Date'].max())][['CBSA Title','Admin2','Date','Population','Daily Confirmed Cases']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#county totals summary for CA\n",
    "us_daily.loc[us_daily['Province_State']=='California'].groupby(['Admin2'])[['Population','Daily Confirmed Cases', 'Daily Dead']].agg({'Population':'mean','Daily Confirmed Cases':'sum', 'Daily Dead':'sum'}).sort_values('Daily Confirmed Cases', ascending = False)[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_daily['Date'].unique()[-30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_lastmonth = us_daily.loc[(us_daily['Admin2']=='San Francisco')&(us_daily['Date'].isin(us_daily['Date'].unique()[-30:]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3208 cases in SF county in the last month\n",
    "sf_lastmonth['Daily Confirmed Cases'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#US census estimate for SF county population in 2019\n",
    "sf_lastmonth['Population'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .4 cases per 100 capita. Less than one in 100 are actively transmissible\n",
    "sf_lastmonth['Daily Confirmed Cases'].sum()/sf_lastmonth['Population'].values[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .82 cases per 100 capita. Less than one in 100 have tested positive\n",
    "us_daily.loc[(us_daily['Admin2']=='San Francisco')]['Daily Confirmed Cases'].sum()/sf_lastmonth['Population'].values[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_daily.loc[(us_daily['Admin2']=='San Francisco')]['Daily Confirmed Cases'].sum()/(sf_lastmonth['Population'].values[0]-us_daily.loc[(us_daily['Admin2']=='San Francisco')]['Daily Confirmed Cases'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.008266986610180929 * 100 * 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100 - (20000/(330000000-20000))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPENDIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spreadsheetId': '1kQEyp1E5gDs6DE3WPn8w71zxAWqpXH7qHKkcfKlsvtk',\n",
       " 'updatedRange': 'Sheet1!A1:L411001',\n",
       " 'updatedRows': 411001,\n",
       " 'updatedColumns': 12,\n",
       " 'updatedCells': 4932012}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initial Load\n",
    "gc = gspread.service_account(filename='./covid-19-data/client_secret.json')\n",
    "sheet = gc.open(\"COVID Tableau Automation 1\").sheet1\n",
    "\n",
    "#delete extraneous columns to make room for more rows:\n",
    "sheet.delete_columns(13,26)\n",
    "\n",
    "us_daily_1 = us_daily.copy().loc[us_daily['Date'].isin(us_daily['Date'].unique()[:125])]\n",
    "sheet.update([us_daily_1.columns.values.tolist()] + us_daily_1.values.tolist())\n",
    "\n",
    "#2nd spreadsheet\n",
    "sheet2 = gc.open(\"COVID Tableau Automation 2\").sheet1\n",
    "\n",
    "sheet2.delete_columns(13,26)\n",
    "\n",
    "us_daily_2 = us_daily.copy().loc[us_daily['Date'].isin(us_daily['Date'].unique()[125:])]\n",
    "sheet2.update([us_daily_2.columns.values.tolist()] + us_daily_2.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.oauth2 import service_account\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_file('./covid-19-data/client_secret.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url3 = 'https://covidtracking.com/api/v1/states/daily.csv'\n",
    "df_testing = pd.read_csv(url3,error_bad_lines = False)\n",
    "\n",
    "df_testing = df_testing.rename(columns = {'date':'Date','state':'Province_State'})\n",
    "df_testing[['totalTestResultsIncrease','positiveIncrease','negativeIncrease','totalTestResults','positive','negative']] = df_testing[['totalTestResultsIncrease','positiveIncrease','negativeIncrease','totalTestResults','positive','negative']].fillna(0)\n",
    "\n",
    "to_fix = ['totalTestResultsIncrease','positiveIncrease','negativeIncrease']\n",
    "actual = ['totalTestResults','positive','negative']\n",
    "columns = df_testing.columns\n",
    "def fill_func(states):\n",
    "    for state in states:\n",
    "        for col in range(0,len(to_fix)):\n",
    "            cumsum = df_testing.loc[df_testing['Province_State']==state].sort_values(by='Date')[to_fix[col]].cumsum()\n",
    "            actualsum = df_testing.loc[df_testing['Province_State']==state,['Date',actual[col]]].sort_values(by='Date')[actual[col]]\n",
    "            comparison = cumsum.eq(actualsum)\n",
    "            if comparison[comparison == False].count() > 0:\n",
    "                Earliest_index = comparison[comparison == False].index[0]\n",
    "                df_testing.iloc[Earliest_index,columns.get_loc(to_fix[col])] = df_testing.iloc[Earliest_index,columns.get_loc(actual[col])]\n",
    "                \n",
    "fill_func(df_testing['Province_State'].unique())\n",
    "df_testing = df_testing.replace({'Province_State':states})\n",
    "df_testing['Date'] = pd.to_datetime(df_testing['Date'], format='%Y%m%d').apply(lambda x: pd.datetime.strftime(x, '%m/%d/%y'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing CBSA codes after merge: 41980, 10380, 38660, 11640, 41900, 49500, 32420, 25020, 27580, 17620, 17640, 42180\n",
    "#They're all in Puerto Rico. Span across multiple CBSA and CSA. Should just ignore\n",
    "res = Counter(df_counties['CBSA Code'].value_counts().to_dict()) - Counter(df_usconf['CBSA Code'].value_counts().to_dict())\n",
    "pd.set_option('display.max_rows', None)\n",
    "df_counties[df_counties['CBSA Code'].isin(list(res.keys()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_usconf.loc[df_usconf['UID']==630,['CBSA Code', 'CBSA Title', 'CSA Code', 'CSA Title']] = [41980,'San Juan-Bayamón-Caguas, PR', 490.0, 'San Juan-Bayamón, PR']\n",
    "df_usconf.loc[df_usconf['UID']==630][['CBSA Code', 'CBSA Title', 'CSA Code', 'CSA Title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove = ['iso2', 'iso3', 'code3', 'Combined_Key']\n",
    "df_usconf = df_usconf[Counter(df_usconf.columns.tolist()) - Counter(columns_to_remove)]\n",
    "df_usdead = df_usdead[Counter(df_usdead.columns.tolist()) - Counter(columns_to_remove)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add additional column for CBSAs and CSAs before melting?\n",
    "\n",
    "'''BA_counties = ['Alameda','Contra Costa','Marin','Napa','San Francisco','San Mateo','Santa Clara','Solano','Sonoma']\n",
    "LA_counties =['Ventura','San Bernadio', 'Riverside', 'Los Angeles', 'Orange']'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#California and Texas total confirmed cases differ by 2000+. Stick to COVIDTESTING data for testing dataframe\n",
    "totalgrp = us_totals.groupby(['Province_State','Date'], as_index=False)['Total Confirmed Cases','Total Dead'].sum()\n",
    "comparison = df_testing.loc[df_testing['Date']=='07/27/20', ['Province_State','Date','positive']].merge(totalgrp.loc[totalgrp['Date']=='07/27/20',['Province_State','Date','Total Confirmed Cases']], on=['Province_State','Date'], how = 'left', suffixes = (False, False))\n",
    "comparison['Delta'] = comparison['positive'] - comparison['Total Confirmed Cases']\n",
    "comparison"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
